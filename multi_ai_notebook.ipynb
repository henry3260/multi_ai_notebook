{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henry3260/multi_ai_notebook/blob/main/multi_ai_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MWOf8JhoRSW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb6f01b-670c-4f5e-c3fd-4ceb6bb11076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2rihCMgtfcuPOCmF6rWRickeWRA_7hrNfFZndJtEpKh5m5GrM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZhuBVfxBCc_",
        "outputId": "41100648-8877-4436-ae69-3fa840a11259"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozek5tPyz67p",
        "outputId": "21f86761-a5ec-4916-bb1b-22188223edf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template, redirect, url_for\n",
        "import google.generativeai as genai\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoModelForQuestionAnswering\n",
        "from werkzeug.utils import secure_filename\n",
        "import torch\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# 設置ngrok授權碼\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = \"2rihCMgtfcuPOCmF6rWRickeWRA_7hrNfFZndJtEpKh5m5GrM\"\n",
        "# 把google drive上的templates抓下來\n",
        "# shutil.copytree(\"/content/drive/MyDrive/templates\", \"/content/templates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "9D7qQbF0z1vu",
        "outputId": "87aef29f-4d22-4568-e75e-57495530a4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: <s>\n",
            "ngrok URL: NgrokTunnel: \"https://1967-35-197-101-98.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 17:59:10] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 17:59:11] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 17:59:39] \"POST /generate_text HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 配置 Google Generative AI API 密鑰\n",
        "genai.configure(api_key=\"AIzaSyDK29oPl7H1i0Gsqt-WgrUWxM06_RdvIA0\")\n",
        "API_URL = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"\n",
        "# 明確指定 templates 資料夾的位置\n",
        "app = Flask(__name__, template_folder=\"/content/drive/MyDrive/templates\")\n",
        "\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# 上傳圖片的設定\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "# 確保上傳資料夾存在\n",
        "if not os.path.exists(UPLOAD_FOLDER):\n",
        "    os.makedirs(UPLOAD_FOLDER)\n",
        "\n",
        "# 判斷檔案類型\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "# 設置主頁\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/generate_text', methods=['POST'])\n",
        "def generate_text():\n",
        "    # 獲取文字輸入\n",
        "    user_input = request.form.get('user_input', '')  # 如果未提供文字輸入，設置為空字符串\n",
        "\n",
        "    # 處理圖片文件\n",
        "    file = request.files.get('file')  # 獲取上傳的文件\n",
        "    file_description = \"\"\n",
        "\n",
        "    if file and allowed_file(file.filename):  # 檢查文件是否有效\n",
        "        filename = secure_filename(file.filename)\n",
        "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "        file.save(filepath)\n",
        "\n",
        "        # 使用 AI 模型生成圖片描述\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        file_response = model.generate_content(f\"Generate description for this image: {filepath}\")\n",
        "        file_description = file_response.text\n",
        "\n",
        "    # 使用 AI 模型生成文字內容\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    text_response = model.generate_content(user_input)\n",
        "    text_description = text_response.text\n",
        "\n",
        "\n",
        "\n",
        "    # 渲染結果頁面，將文字和圖片描述一起傳遞\n",
        "    return render_template(\n",
        "        'result.html',\n",
        "        text_result=text_description,\n",
        "        file_result=file_description\n",
        "    )\n",
        "\n",
        "\n",
        "context = \"Your context here\"\n",
        "question = \"Your question here\"\n",
        "\n",
        "inputs = tokenizer(question, context, return_tensors='pt')\n",
        "outputs = model(**inputs)\n",
        "\n",
        "start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "answer_start = torch.argmax(start_logits)\n",
        "answer_end = torch.argmax(end_logits) + 1\n",
        "\n",
        "answer = tokenizer.decode(inputs['input_ids'][0][answer_start:answer_end])\n",
        "print(f\"Answer: {answer}\")\n",
        "\n",
        "def start_flask_with_ngrok():\n",
        "    # # 啟動 ngrok 隧道\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"ngrok URL: {public_url}\")\n",
        "\n",
        "    # 啟動 Flask 應用\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n",
        "# 啟動應用\n",
        "if __name__ == \"__main__\":\n",
        "    start_flask_with_ngrok()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1I8EpSnQl5zlPTdjZzl4lcUDoWQdiluyj",
      "authorship_tag": "ABX9TyNDjd7LJVruKQD849ddHe5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}